{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_key = \"5b1d8775f8fd485e9fd2bea8c1d21d16\"\n",
    "assert subscription_key\n",
    "search_url = \"https://api.bing.microsoft.com/v7.0/search\"\n",
    "search_term = \"fintech faculty site:harvard.edu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "headers = {\"Ocp-Apim-Subscription-Key\": subscription_key}\n",
    "params = {\"q\": search_term, \"textDecorations\": True, \"textFormat\": \"HTML\"}\n",
    "response = requests.get(search_url, headers=headers, params=params)\n",
    "response.raise_for_status()\n",
    "search_results = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "rows = \"\\n\".join([\"\"\"<tr>\n",
    "                       <td><a href=\\\"{0}\\\">{1}</a></td>\n",
    "                       <td>{2}</td>\n",
    "                     </tr>\"\"\".format(v[\"url\"], v[\"name\"], v[\"snippet\"])\n",
    "                  for v in search_results[\"webPages\"][\"value\"]])\n",
    "HTML(\"<table>{0}</table>\".format(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import urllib.request, urllib.error, urllib.parse\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import en_core_web_lg\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "counter =0\n",
    "for searchresult in search_results[\"webPages\"][\"value\"]:\n",
    "    url = searchresult[\"url\"]\n",
    "    print(url)\n",
    "    try:   \n",
    "        response = get(url).content\n",
    "        soup = BeautifulSoup(response)\n",
    "        for script in soup([\"script\", \"style\"]):\n",
    "            script.extract()\n",
    "        counter = counter+1\n",
    "        f= open(str(counter)+\".txt\",\"w\",encoding='utf-8')\n",
    "        #print(counter)\n",
    "        cleanedtext = soup.text.strip('\\t\\r\\n')\n",
    "        f.write(cleanedtext)\n",
    "        f.close()\n",
    "        doc = nlp(cleanedtext)\n",
    "        for ent in doc.ents:\n",
    "            if(ent.label_ == 'PERSON'):\n",
    "                print(ent.text)\n",
    "    except:\n",
    "        print(\"ERROR HAPPENED\")\n",
    "        # doc = nlp(soup.text.strip('\\t\\r\\n'))\n",
    "        # for ent in doc.ents:\n",
    "        #     if(ent.label_ == 'PERSON'):\n",
    "        #         print(ent.text)\n",
    "    # except error:\n",
    "    #     print(error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}